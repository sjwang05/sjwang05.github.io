---
title: Toy SAT Solver (Part 2)
published: true
---

This is the second post in my SAT Solver blog series. Last time, we wrote a
simple lexer that generated a stream of tokens from strings in CNF. Today, we'll
write a parser that accepts this token stream and produces an AST.

## Defining an AST

As a reminder from last time, the context-free grammar for CNF looks like this:

```none
EXPR := CLAUSE ( "and" CLAUSE )*
CLAUSE := "(" TERM ( "or" TERM )* ")"
TERM := ( "not" )? LIT
LIT := "true" | "false" | [a-zA-Z0-9]+
```

When we're producing the AST, we'll completely discard parentheses: precedence is
implicit in the structure of the AST and through how CNF is defined. We'll also
omit boolean operators in AST nodes for similar reasons: certain operators cannot
appear outside certain positions in a CNF expression by definition. Instead, we'll
represent an `Expr` as a list of `Clause`s, and a `Clause` as a list of `Term`s.
Terms have two polarities, so we'll encode that as two variants: `Just` and `Not`.
Additionally, we need to keep track of a list of variables to substitute into when
solving expressions. We'll build up that list while parsing and store it as part
of the AST.

Here's what all that looks like in Rust:

```rust
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Ast {
    pub root: Expr,
    // We use a BTreeSet of names instead of a HashSet because we need
    // to hash names, and HashSet doesn't `impl Hash`
    pub names: BTreeSet<Ident>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Expr {
    pub clauses: Vec<Clause>,
}

impl Expr {
    pub fn len(&self) -> usize {
        self.clauses.len()
    }

    pub fn is_empty(&self) -> bool {
        self.clauses.is_empty()
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Clause {
    pub operands: Vec<Unary>,
}

impl Clause {
    pub fn new_false() -> Self {
        Self {
            operands: vec![Unary::Just(Term::Bool(false))],
        }
    }

    pub fn len(&self) -> usize {
        self.operands.len()
    }

    pub fn is_empty(&self) -> bool {
        self.operands.is_empty()
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum Unary {
    Not(Term),
    Just(Term),
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum Term {
    Bool(bool),
    Var(Ident),
}
```

We've also included a few utility methods that'll be helpful when solving
expressions. Like last time, we'll write a few more. First, starting with `Clause`:

```rust
// In `impl Clause`:
    pub fn is_true(&self) -> bool {
        // We can't just do !self.is_false() because a clause may still contain
        // unevaluated variables, in which case it is neither true nor false.
        !self.operands.is_empty()
            && (self.operands == vec![Unary::Just(Term::Bool(true))]
                || self
                    .operands
                    .iter()
                    .all(|operand| *operand == Unary::Just(Term::Bool(true))))
    }

    pub fn is_false(&self) -> bool {
        // Our grammar disallows empty clauses in the input string, so we know all empty clauses
        // are the result of `false` being filtered out.
        self.operands.is_empty()
            || self.operands == vec![Unary::Just(Term::Bool(false))]
            || self
                .operands
                .iter()
                .all(|operand| *operand == Unary::Just(Term::Bool(false)))
    }
```

These will come in handy when evaluating expressions. We'll also write a few for
`Term`, which we'll use when creating `Term`s in our parser:

```rust
impl TryFrom<Token> for Term {
    type Error = anyhow::Error;

    fn try_from(value: Token) -> Result<Self, Self::Error> {
        match value.kind {
            TokenKind::Dummy | TokenKind::Paren(_) | TokenKind::Op(_) => Err(anyhow!(
                "Term::try_from called on a non-literal token: {:?}",
                value.kind
            )),
            TokenKind::Lit(kind) => Ok(kind.into()),
        }
    }
}

impl From<LitKind> for Term {
    fn from(value: LitKind) -> Self {
        match value {
            LitKind::Var(ident) => Self::Var(ident),
            LitKind::Bool(val) => Self::Bool(val),
        }
    }
}
```

Now that we've defined our AST, let's move onto parsing.

## Parsing CNF

Since we already have a grammar for CNF expressions, and the grammar is pretty
simple, writing the parser shouldn't be too difficult. Our parser will need to
keep track of the list of tokens generated by our lexer, the current token it's
looking at, and the set of variable names that appear in our expression:

```rust
pub struct Parser {
    tokens: VecDeque<Token>,
    token: Token,
    names: HashSet<Ident>,
}

impl Parser {
    pub fn new(tokens: VecDeque<Token>) -> Self {
        Self {
            tokens,
            token: Token::new_dummy(),
            names: Default::default(),
        }
    }

    fn bump(&mut self) -> Result<()> {
        self.token = self
            .tokens
            .pop_front()
            .ok_or(anyhow!("tokens are empty!"))?;
        Ok(())
    }
}
```

Next, we'll define our entry point for parsing. As with our lexer, we want this
method to consume our parser, since once our parser's done munching on our token
stream, it wouldn't make sense for us to call `parse()`--or anything, for that matter--again.

```rust
// impl Parser
    pub fn parse(mut self) -> Result<Ast> {
        self.tokens.push_back(Token::new_dummy());
        self.bump()?;
        Ok(Ast {
            root: self.parse_expr()?,
            names: self.names,
        })
    }

    fn bump(&mut self) -> Result<()> {
        self.token = self
            .tokens
            .pop_front()
            .ok_or(anyhow!("tokens are empty!"))?;
        Ok(())
    }
```

Notice we call `bump()` before doing anything else--that's because we want to
replace the `Dummy` token we
initialized `token` with the actual first token in `self.tokens`. Additionally,
we push a `Dummy` token to the back of our queue so we know when we've hit the
end of the expression.

We'll start at the top level of our grammar, namely, `Expr`:

```rust
// impl Parser
    fn parse_expr(&mut self) -> Result<Expr> {
        let mut clauses = vec![self.parse_clause()?];
        while matches!(self.token.kind, TokenKind::Op(OpKind::And)) {
            _ = self.bump();
            clauses.push(self.parse_clause()?);
        }
        Ok(Expr { clauses })
    }
```

It's a pretty direct translation of our context-free grammar: an `Expr` is just
a list of clauses joined by the `and` operator. We ignore the `Result` returned
by `self.bump()` because we don't care if we're out of tokens or not--our
methods deeper in the call stack will produce an error if we unexpectedly hit
the end of an expression.

Parsing clauses looks very similar:

```rust
// impl Parser
    fn parse_clause(&mut self) -> Result<Clause> {
        self.eat_expect(&[TokenKind::Paren(Open::Open)])?;
        let mut operands = vec![self.parse_unary()?];
        while matches!(self.token.kind, TokenKind::Op(OpKind::Or)) {
            _ = self.bump();
            operands.push(self.parse_unary()?);
        }
        self.eat_expect(&[TokenKind::Paren(Open::Closed)])?;
        Ok(Clause { operands })
    }
```

As with `Expr`s, it's a very literal translation: clauses are just a list of
unary expressions separated by the `or` operator.

We introduce a new method here, `eat_expect()`:

```rust
// impl Parser
    fn eat_expect(&mut self, expected: &[TokenKind]) -> Result<()> {
        if expected.contains(&self.token.kind) {
            _ = self.bump();
            Ok(())
        } else {
            Err(anyhow!(
                "expected one of {expected:?}, found {:?}",
                self.token.kind
            ))
        }
    }
```

It consumes the current token only if it's one of the tokens we're expecting;
otherwise, if we're parsing an ill-formed expression like `(a or) and`, it'll
return an `Err`.

Now we move onto parsing unary expressions. Unlike clauses and top-level
expressions, we don't allow repeated operators--that is, `not not not x` is
disallowed. Here's what that looks like:

```rust
// impl Parser
    fn parse_lit(&mut self) -> Result<Term> {
        if let TokenKind::Lit(LitKind::Bool(val)) = self.token.kind {
            self.bump()?;
            Ok(Term::Bool(val))
        } else if let TokenKind::Lit(LitKind::Var(ident)) = self.token.kind.clone() {
            self.bump()?;
            self.names.insert(ident.clone());
            Ok(Term::Var(ident))
        } else {
            Err(anyhow!("unexpected token {:?}", self.token))
        }
    }
```

Notice we have to `clone()` `self.token` in the second branch: that's because
we're binding the value of `self.token.kind` to the variable `ident` in the
pattern of our `if let`, and since `Ident`s are just newtyped `String`s and
therefore don't `impl Copy`, we'd be trying to move out of `self`, which is
behind a mutable reference. We don't run into this kind of error in the first
branch since `val` has type `bool`, which is `Copy`, so we're not moving
anything out of `self`. The `else` branch catches things like `(a or or b)`.

With that, we're done! Let's see what the parser produces for some sample input.

Input:

```none
(a or b) and (not c)
```

Output:

```none
[src/main.rs:32:5] &ast = Ast {
    root: Expr {
        clauses: [
            Clause {
                operands: [
                    Just(
                        Var(
                            Ident(
                                "a",
                            ),
                        ),
                    ),
                    Just(
                        Var(
                            Ident(
                                "b",
                            ),
                        ),
                    ),
                ],
            },
            Clause {
                operands: [
                    Not(
                        Var(
                            Ident(
                                "a",
                            ),
                        ),
                    ),
                ],
            },
        ],
    },
    names: {
        Ident(
            "b",
        ),
        Ident(
            "a",
        ),
    },
}
```

Looks good! Let's also write a few test cases to make sure we catch invalid grammar.

```rust
#[test]
#[should_panic]
fn bad1() {
    run("(a or) and").unwrap();
}

#[test]
#[should_panic]
fn bad2() {
    run("(a or b) and").unwrap();
}

#[test]
#[should_panic]
fn bad3() {
    run("(a b c) and (d e f)").unwrap();
}
```

We'll use the `#[should_panic]` attribute, whose meaning I hope is pretty
self-explanatory. With that, we're done!

## Conclusion

In this post, we defined the AST for CNF expressions and used the token stream
we produced last time in our parser in order to produce an AST. In the following
post, we'll define an interface for AST visitors and implement a visitor to
detect and simplify certain simple patterns in our AST. We'll then use that
visitor in a very slow, very naive solver to determine expression satisfiability.
